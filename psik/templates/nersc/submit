#!/usr/bin/env python3
#
# Use the NERSC sfapi_client to submit the job. 
#
# psik hot-start and the jobndx are added to the script,
# and the client polls the returned task to extract the jobid.

import os
import sys
import asyncio
import json
from pathlib import Path

from psik.zipstr import dir_to_str

from sfapi_client import AsyncClient
from sfapi_client.compute import Machine

async def main(argv):
    keypath = Path(os.environ["HOME"]) / ".superfacility" / "key.pem"

    with open("{{base}}/spec.json", "r", encoding="utf-8") as f:
        jobspec = json.dumps(json.load(f),separators=(',', ':'))

    # zip up the contents of the working dir.
    zstr = dir_to_str("{{job.directory}}")
    jobndx = int(argv[1])
    with open("{{base}}/scripts/job", "r", encoding="utf-8") as f:
        script = f.read() % {
                'jobspec': jobspec.replace("'", "''"),
                'jobndx': jobndx,
                'zstr': zstr }

    # Note: beware the dreaded {"detail":"Not authenticated"}
    async with AsyncClient(key=keypath) as client:
        user = await client.user()
        user_name = user.name
        user_home = f'/global/homes/{user_name[0]}/{user_name}'
        machine = await client.compute(Machine["perlmutter"])
        job = await machine.submit_job(script)
        print(job.jobid)

if __name__=="__main__":
    asyncio.run(main(sys.argv))
